---
title: OpenAI Providers
slug: /providers/openai
image: "https://og.composio.dev/api/og?title=OpenAI%20Providers"   # image for socials
keywords: ""
hide-nav-links: false
---

The OpenAI Provider is the default provider for the Composio SDK. It transforms Composio tools into a format compatible with OpenAI's function calling capabilities through both: the Responses and Chat Completion APIs.

## Setup
By default the OpenAI Provider is installed when you install the Composio SDK. You can also install it manually:

<CodeGroup>
```typescript TypeScript
npm install @composio/openai
```
```python Python
pip install composio[openai]
```
</CodeGroup>
The OpenAI Provider is used by default when you initialize the Composio SDK but you can explicitly specify it.

<CodeGroup>
```typescript
import { Composio } from "@composio/core";
import { OpenAIProvider } from "@composio/openai";
import { OpenAI } from "openai";

const composio = new Composio({
  apiKey: "your-composio-api-key",
  provider: new OpenAIProvider(),
});

const openai = new OpenAI();
```

```python
from openai import OpenAI
from composio import Composio
from composio_openai import OpenAIProvider

# Initialize tools.
openai_client = OpenAI()
composio = Composio(provider=OpenAIProvider())
```
</CodeGroup>


## Responses API

> Handling tool calls from the Responses API
- [ ] Pending on SDK

### Streaming
> Handling streaming responses from the Responses API
- [ ] Pending on SDK

## Chat Completion API

<CodeGroup>
```typescript {15}
const userId = "your@example.com";
const tools = await composio.tools.get(userId, "HACKERNEWS");

const completion = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [
    {
      role: "user",
      content: "What is the latest hackernews post about?",
    },
  ],
  tools: tools,
});

const result = await composio.provider.handleToolCall(userId, completion);

console.log(result);
```
```python
# Get GitHub tools that are pre-configured
tools = composio.tools.get(user_id="default", toolkits=["GITHUB"])

# Get response from the LLM
response = openai_client.chat.completions.create(
    model="gpt-4-turbo-preview",
    tools=tools,
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": task},
    ],
)
print(response)

# Execute the function calls.
# import ipdb; ipdb.set_trace()
result = composio.provider.handle_tool_calls(response=response, user_id="default")
print(result)
```

</CodeGroup>

{/* The tools can also be called manually:

<CodeGroup>
```typescript {20-27} maxLines={60}
const userId = "your@example.com";
const tools = await composio.tools.get(userId, {
  toolkits: ["HACKERNEWS"],
});

const completion = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [
    {
      role: "user",
      content: "What is the latest hackernews post about?",
    },
  ],
  tools: tools,
});

const toolCall = completion.choices[0]?.message.tool_calls?.[0];
if (toolCall) {
  console.log(`âœ… Calling tool ${toolCall.function.name}`);
  const result = await composio.tools.execute(
    toolCall.function.name,
    {
      userId,
      arguments: JSON.parse(toolCall.function.arguments),
    }
  );
  console.log(JSON.stringify(result, null, 2));
}
```

```python

```
</CodeGroup> */}

### Streaming
> Handling streaming responses from the Chat Completion API
- [ ] Pending on SDK

## Modifiers
Modifiers are functions that can be used to intercept and optionally **modify** the schema, the tool call request and the response from the tool call.

OpenAI provider modifiers are the standard framework modifiers.
Read more here: [Framework Modifiers](/docs/modifiers/schema-modifiers)

