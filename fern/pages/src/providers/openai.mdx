---
title: OpenAI provider
slug: /providers/openai
image: "https://og.composio.dev/api/og?title=OpenAI%20Providers"   # image for socials
keywords: ""
hide-nav-links: false
---

The OpenAI provider enables tool calling support for [OpenAI](https://openai.com/)'s Chat Completions API and Responses API, and is the default provider for the Composio SDK.

## Overview

OpenAI is the default provider for Composio. When you initialize Composio without specifying a provider, it automatically uses the OpenAI provider. The provider supports both:

- **Chat Completions API** - Standard function calling with chat messages
- **Responses API** - Advanced assistant-based interactions with persistent threads

## Setup

### Installation

The OpenAI provider is included with the base Composio SDK installation:

<CodeGroup>
```bash Python
pip install composio
```
```bash TypeScript
npm install @composio/core
```
</CodeGroup>

### Basic initialization

Since OpenAI is the default provider, you can initialize Composio without any additional configuration:

<CodeGroup>
```python Python
from composio import Composio

# OpenAI provider is used by default
composio = Composio()
```
```typescript TypeScript
import { Composio } from '@composio/core';

// OpenAI provider is used by default
const composio = new Composio();
```
</CodeGroup>

### Explicit provider initialization

If you want to explicitly specify the OpenAI provider or pass custom configuration:

<CodeGroup>
```python Python
from composio import Composio
from composio_openai import OpenAIProvider

# Explicitly use OpenAI provider
composio = Composio(provider=OpenAIProvider())
```
```typescript TypeScript
import { Composio } from '@composio/core';
import { OpenAIProvider } from '@composio/openai';

// Explicitly use OpenAI provider
const composio = new Composio({ provider: new OpenAIProvider() });
```
</CodeGroup>

## Responses API

The Responses API provides advanced assistant capabilities with persistent threads and built-in tool execution. This is ideal for building stateful, multi-turn conversations.

### Basic setup

<CodeGroup>
<SnippetCode
  src="fern/snippets/providers/python/openai-responses.py"
  startLine={1}
  endLine={23}
/>
<SnippetCode
  src="fern/snippets/providers/typescript/openai-responses.ts"
  startLine={1}
  endLine={24}
/>
</CodeGroup>

### Running assistants with tools

<CodeGroup>
<SnippetCode
  src="fern/snippets/providers/python/openai-responses.py"
  startLine={25}
  endLine={49}
/>
<SnippetCode
  src="fern/snippets/providers/typescript/openai-responses.ts"
  startLine={26}
  endLine={49}
/>
</CodeGroup>

<Note>
The Responses API maintains conversation context across multiple interactions, making it ideal for complex, multi-step workflows.
</Note>

## Chat Completions API

The Chat Completions API provides stateless function calling for immediate tool execution.

### Basic setup

<CodeGroup>
<SnippetCode
  src="fern/snippets/providers/python/openai-provider.py"
  startLine={9}
  endLine={25}
/>
<SnippetCode
  src="fern/snippets/providers/typescript/openai.ts"
  startLine={26}
  endLine={45}
/>
</CodeGroup>

<Note>
Tools like **GMAIL**, **SLACK**, and **GITHUB** require authenticated connections. Before using these tools, ensure the user has connected their account. See [Connecting accounts](/docs/authentication/connected-accounts) for setup instructions.
</Note>

## Tool execution

Both APIs handle tool execution seamlessly:

<AccordionGroup>
  <Accordion title="Chat Completions API">
    The Chat Completions API returns tool calls that need to be executed:
    
    <CodeGroup>
    <SnippetCode
      src="fern/snippets/providers/python/openai-provider.py"
      startLine={22}
      endLine={24}
    />
    <SnippetCode
      src="fern/snippets/providers/typescript/openai.ts"
      startLine={27}
      endLine={29}
    />
    </CodeGroup>
  </Accordion>
  
  <Accordion title="Responses API">
    The Responses API handles tool execution automatically during the run:
    
    <CodeGroup>
    <SnippetCode
      src="fern/snippets/providers/python/openai-responses.py"
      startLine={42}
      endLine={47}
    />
    <SnippetCode
      src="fern/snippets/providers/typescript/openai-responses.ts"
      startLine={40}
      endLine={45}
    />
    </CodeGroup>
  </Accordion>
</AccordionGroup>


## Modifiers
Modifiers are functions that can be used to intercept and optionally **modify** the schema, the tool call request and the response from the tool call.

OpenAI provider modifiers are the standard framework modifiers.
Read more here: [Modifying tool schemas](/docs/modifying-tool-schemas)

