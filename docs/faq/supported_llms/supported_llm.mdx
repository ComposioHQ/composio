---
title: "üõ†Ô∏è What LLMs can I use?"
sidebarTitle: "Supported LLMs"
icon: "code"
description: "Understand more about Actions"
---

Composio is LLM Agnostic, which means it is not dependent on any specific LLM. You can use any LLM from any of the providers
including OpenAI, Anthropic, Google, Groq, Cerebras, Ollama and so on.

By default you can use LLMs from any of the frameworks including Langchain, LlamaIndex, Groq etc.,
<AccordionGroup>
<Accordion title="Ollama (Open Source Models)">
<CodeGroup>
```python Python
import openai
from composio_openai import ComposioToolSet, App, Action

openai.base_url = "http://localhost:11434/v1"
openai.api_key = 'ollama'
toolset = ComposioToolSet(api_key="COMPOSIO_API_KEY")

messages=[{'role': 'user', 'content': 'Star the repo composiohq/composio'}]

tools = toolset.get_tools(apps=[App.GITHUB])
response = openai.chat.completions.create(
	model="llama3.1",
	messages=messages,
	tools=tools,
)
```

```javascript Javascript
import OpenAI from 'openai'
import { OpenAIToolSet } from "composio-core";

const toolset = new OpenAIToolSet({apiKey: COMPOSIO_API_KEY,});

const openai = new OpenAI({
  baseURL: 'http://localhost:11434/v1',
  apiKey: 'ollama', // required but unused
})
const tools = await toolset.getTools({ actions: ["GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER"] }, entity.id);
const instruction = `Star the repo composiohq/composio`

const completion = await openai.chat.completions.create({
  model: 'llama3.1',
  messages: [{ role: 'user', content: instruction }],
  tools: tools,
})

console.log(completion.choices[0].message.content)

```
</CodeGroup>
</Accordion>
<Accordion title="Cerebras">
```python Python
import os
import dotenv
from composio_llamaindex import Action, App, ComposioToolSet
from composio_llamaindex import App, ComposioToolSet, Action
from llama_index.core.agent import FunctionCallingAgentWorker
from llama_index.core.llms import ChatMessage
from llama_index.core.llms import Cerebras
from datetime import datetime
from llama_index.core import Settings

# Load environment variables from .env file
dotenv.load_dotenv()
Settings.llm = Cerebras(model="llama3.1-70b", api_key=os.environ["GROQ_API_KEY"])
llm = Cerebras(model="llama3.1-70b", api_key=os.environ["GROQ_API_KEY"])


# Initialize the ComposioToolSet
toolset = ComposioToolSet()

# Get the RAG tool from the Composio ToolSet
tools = toolset.get_tools(apps=[App.GOOGLECALENDAR])

# Retrieve the current date and time
date = datetime.today().strftime("%Y-%m-%d")
timezone = datetime.now().astimezone().tzinfo

# Setup Todo
todo = """
    1PM - 3PM -> Code,
    5PM - 7PM -> Meeting,
    9AM - 12AM -> Learn something,
    8PM - 10PM -> Game
"""

# Define the RAG Agent
prefix_messages = [
    ChatMessage(
        role="system",
        content=(
        """
        You are an AI agent responsible for taking actions on Google Calendar on users' behalf. 
        You need to take action on Calendar using Google Calendar APIs. Use correct tools to run APIs from the given tool-set.
        """
        ),
    )
]

# Initialize a FunctionCallingAgentWorker with the tools, LLM, and system messages
agent = FunctionCallingAgentWorker(
    tools=tools,  # Tools available for the agent to use
    llm=llm,  # Language model for processing requests
    prefix_messages=prefix_messages,  # Initial system messages for context
    max_function_calls=10,  # Maximum number of function calls allowed
    allow_parallel_tool_calls=False,  # Disallow parallel tool calls
    verbose=True,  # Enable verbose output
).as_agent()

response = agent.chat(
    """
Book slots according to {todo}. 
Properly Label them with the work provided to be done in that time period. 
Schedule it for today. Today's date is {date} (it's in YYYY-MM-DD format) 
and make the timezone be {timezone}.
    """
)
print(response)
```
</Accordion>
</AccordionGroup>